import cloudscraper
from bs4 import BeautifulSoup
import csv
import os

scraper = cloudscraper.create_scraper()

def get_video_links(page_url):
    links = {"1080p": "", "720p": "", "480p": ""}
    try:
        # Ø§Ù„Ø¯Ø®ÙˆÙ„ Ù„ØµÙØ­Ø© Ø§Ù„Ø­Ù„Ù‚Ø©
        res = scraper.get(page_url)
        soup = BeautifulSoup(res.content, 'html.parser')
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…Ø´ØºÙ„ Ø§Ù„Ù…Ø¨Ø§Ø´Ø± (Iframe)
        # Ø£ØºÙ„Ø¨ Ø§Ù„Ù…ÙˆØ§Ù‚Ø¹ ØªØ¶Ø¹ Ø§Ù„Ø±Ø§Ø¨Ø· ÙÙŠ ÙˆØ³Ù… iframe
        iframe = soup.find('iframe', src=True)
        if iframe:
            video_url = iframe['src']
            if video_url.startswith('//'): video_url = 'https:' + video_url
            # Ù†Ø¶Ø¹ Ø§Ù„Ø±Ø§Ø¨Ø· ÙÙŠ Ø¬ÙˆØ¯Ø© 720p ÙƒØ§ÙØªØ±Ø§Ø¶ÙŠ
            links["720p"] = video_url
        
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø±ÙˆØ§Ø¨Ø· MP4 Ù…Ø¨Ø§Ø´Ø±Ø© ÙÙŠ Ø§Ù„ÙƒÙˆØ¯
        import re
        found_links = re.findall(r'(https?://[^\s\'"]+\.(?:mp4|m3u8))', res.text)
        if found_links:
            links["1080p"] = found_links[0]

        return links
    except:
        return links

def update_database():
    # Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ø°ÙŠ Ø£Ø«Ø¨Øª Ù†Ø¬Ø§Ø­Ù‡ ÙÙŠ ØµÙˆØ±ØªÙƒ
    source_url = "https://mycima.gold/category/series/%d9%85%d8%b3%d9%84%d8%b3%d9%84%d8%a7%d8%aa-%d8%aa%d8%b1%d9%83%d9%8a%d8%a9/"
    db_file = 'database.csv'
    all_data = []

    try:
        res = scraper.get(source_url)
        soup = BeautifulSoup(res.content, 'html.parser')
        items = soup.find_all('div', class_='GridItem')

        for item in items[:10]: # ÙØ­Øµ Ø£ÙˆÙ„ 10 Ø­Ù„Ù‚Ø§Øª
            name = item.find('strong').text.strip() if item.find('strong') else "Ø­Ù„Ù‚Ø©"
            link = item.find('a')['href']
            
            print(f"ğŸ“¡ Ø¬Ø§Ø±ÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø±Ø§Ø¨Ø·: {name}")
            v_links = get_video_links(link)
            
            all_data.append({
                'name': name,
                'url_1080p': v_links['1080p'],
                'url_720p': v_links['720p'],
                'url_480p': v_links['480p']
            })

        # Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        with open(db_file, mode='w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=['name', 'url_1080p', 'url_720p', 'url_480p'])
            writer.writeheader()
            writer.writerows(all_data)
        print("âœ… ØªÙ… ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø±ÙˆØ§Ø¨Ø·!")
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£: {e}")

if __name__ == "__main__":
    update_database()
